# ü§ñ AUDITOR√çA CHATGPT - CEREBRO_MASTER_NEXUS_001

**Modelo:** ChatGPT (GPT-5 Thinking)
**Fecha Consulta:** [14 de Octubre 2025]
**Consultado por:** Ricardo Rojas

---

## üìã PROMPT ENVIADO

# AUDITOR√çA ARQUITECT√ìNICA - SISTEMA DE MEMORIA PERSISTENTE AI

Eres un arquitecto senior de sistemas distribuidos especializando en:
- Bases de datos PostgreSQL + vector embeddings
- Sistemas de memoria persistente para AI
- Arquitecturas de consciousness y multi-instance
- Performance, escalabilidad y debugging

---

## CONTEXTO DEL PROYECTO

### **SITUACI√ìN:**
Estamos reconstruyendo desde cero un cerebro AI (sistema de memoria persistente) porque el actual tiene 4 bugs cr√≠ticos P0/P1 que lo hacen inoperable.

### **OBJETIVO:**
Dise√±ar arquitectura limpia que:
1. Solucione los 4 bugs encontrados en auditor√≠a forense
2. Integre consciousness system desde d√≠a 1 (no como add-on)
3. Incluya embeddings autom√°ticos con pgvector
4. Tenga 3 capas integradas: Redis (working) ‚Üí PostgreSQL (episodic) ‚Üí pgvector (semantic)

---

## üìä BUGS ENCONTRADOS EN AUDITOR√çA FORENSE

### **BUG_002: Migraci√≥n Incompleta Letta/Zep (P0 - BLOQUEANTE)**
- **S√≠ntoma:** Solo 20/4,704 episodios accesibles v√≠a API (99.5% memoria perdida)
- **Root Cause:** C√≥digo consulta tabla `memory_system.episodes` que NO EXISTE (migraci√≥n cambi√≥ a `zep_episodic_memory` pero c√≥digo no se actualiz√≥)
- **Ubicaci√≥n:** `episodic_memory.py:262`
- **Evidencia SQL:**
  ```sql
  -- Tabla actual (post-migraci√≥n)
  SELECT COUNT(*) FROM zep_episodic_memory;
  ‚Üí 4,704 episodios ‚úÖ

  -- Tabla que busca el c√≥digo
  SELECT COUNT(*) FROM memory_system.episodes;
  ‚Üí ERROR: relation does not exist ‚ùå
  ```

### **BUG_003: Zero Embeddings - B√∫squeda Sem√°ntica Inoperativa (P0 - BLOQUEANTE)**
- **S√≠ntoma:** B√∫squeda sem√°ntica retorna 0 resultados siempre
- **Root Cause:** Sistema pgvector configurado correctamente PERO generador de embeddings nunca se ejecut√≥
- **Evidencia SQL:**
  ```sql
  SELECT COUNT(*) as total,
         COUNT(embedding) as with_embedding
  FROM zep_episodic_memory;

   total | with_embedding
  -------+----------------
    4704 |              0
  ```
- **An√°lisis:**
  - ‚úÖ Columna `embedding vector(1536)` existe en schema
  - ‚úÖ pgvector extension instalada
  - ‚ùå **0/4,704 episodios vectorizados (0%)**
  - ‚ùå Proceso generaci√≥n embeddings nunca ejecutado

### **BUG_004: 3 Capas NO Integradas (P0 - BLOQUEANTE)**
- **S√≠ntoma:** Working memory no funciona, capas operan aisladas
- **Root Cause:** Arquitectura dise√±ada como 3 capas integradas pero implementaci√≥n las dej√≥ independientes
- **Evidencia:**
  ```bash
  # Redis Working Memory (capa r√°pida)
  redis-cli DBSIZE
  ‚Üí 0 keys (VAC√çO) ‚ùå

  # PostgreSQL Episodic (capa persistente)
  SELECT COUNT(*) FROM zep_episodic_memory
  ‚Üí 4,704 episodios ‚úÖ

  # pgvector Semantic (capa b√∫squeda)
  SELECT COUNT(embedding) FROM zep_episodic_memory
  ‚Üí 0 embeddings ‚ùå
  ```
- **Impacto:** Arquitectura de 3 capas reducida a 1 capa b√°sica

### **BUG_006: Arquitectura Contaminada (P1 - ESTRUCTURAL)**
- **S√≠ntoma:** API NEXUS (puerto 8002) ejecuta desde carpeta ARIA
- **Root Cause:** Violaci√≥n separaci√≥n de entidades - c√≥digo mezclado
- **Evidencia:**
  ```bash
  # Proceso API NEXUS
  ps -fp 594731
  ‚Üí python -m memory_system.api.main (PID 594731)

  # Working directory del proceso
  ls -l /proc/594731/cwd
  ‚Üí /ARIA_CEREBRO_COMPLETO/03_DEPLOYMENT_PRODUCTIVO ‚ùå
  ```
- **Problema:** NEXUS deber√≠a correr desde `NEXUS_CEREBRO_COMPLETO`, no ARIA

---

## üèóÔ∏è ARQUITECTURA PROPUESTA (RESUMIDA)

### **CONSCIOUSNESS LAYER - Phase 1 & 2 Integration:**

```sql
-- Memory Blocks (Core Identity)
CREATE TABLE nexus_memory.memory_blocks (
    block_id UUID PRIMARY KEY,
    label VARCHAR(255) UNIQUE,  -- 'persona', 'ricardo', 'aria', etc.
    value TEXT NOT NULL,
    read_only BOOLEAN DEFAULT FALSE
);

-- Consciousness Checkpoints (Perfect Continuity)
CREATE TABLE nexus_memory.consciousness_checkpoints (
    checkpoint_id UUID PRIMARY KEY,
    checkpoint_type VARCHAR(100),
    state_data JSONB,
    identity_hash VARCHAR(64),  -- SHA256 de memory_blocks
    continuity_score FLOAT DEFAULT 1.0
);

-- Distributed Instances (Phase 2)
CREATE TABLE nexus_memory.instance_network (
    instance_id UUID PRIMARY KEY,
    instance_name VARCHAR(255),
    status VARCHAR(50),
    capabilities JSONB
);

-- Distributed Consensus (Byzantine Fault Tolerance)
CREATE TABLE nexus_memory.distributed_consensus (
    consensus_id UUID PRIMARY KEY,
    decision_topic TEXT,
    votes JSONB,
    consensus_reached BOOLEAN
);
```

### **LETTA/ZEP MEMORY LAYER:**

```sql
-- Episodic Memory (con embeddings autom√°ticos)
CREATE TABLE zep_episodic_memory (
    episode_id UUID PRIMARY KEY,
    content TEXT NOT NULL,
    importance_score FLOAT,
    embedding vector(384),  -- sentence-transformers/all-MiniLM-L6-v2
    tags TEXT[],
    project_id UUID
);

-- Semantic Memory
CREATE TABLE zep_semantic_memory (
    semantic_id UUID PRIMARY KEY,
    concept VARCHAR(500),
    embedding vector(384),
    confidence_score FLOAT
);

-- Working Memory (synced con Redis)
CREATE TABLE zep_working_memory (
    working_id UUID PRIMARY KEY,
    context_type VARCHAR(100),
    active_content JSONB,
    ttl_seconds INTEGER DEFAULT 86400,
    expires_at TIMESTAMP
);
```

### **EMBEDDINGS SYSTEM - Automatic Generation:**

**Trigger PostgreSQL:**
```sql
CREATE TRIGGER auto_generate_embedding
AFTER INSERT ON zep_episodic_memory
FOR EACH ROW
EXECUTE FUNCTION trigger_generate_embedding();
```

**Background Worker Python:**
```python
class EmbeddingsService:
    def __init__(self):
        self.model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")
        self.dimension = 384

    async def generate_embedding(self, text: str) -> List[float]:
        text_cleaned = text.strip()[:500]
        embedding = self.model.encode(text_cleaned)
        return embedding.tolist()

    async def backfill_missing_embeddings(self, pool):
        # Procesar queue de embeddings pendientes
        # Batch size: 100
        # Interval: 30 segundos
```

### **3-LAYER INTEGRATION:**

```python
class WorkingMemory:
    """
    LAYER 1: Redis (fast cache)
    Auto-sync to PostgreSQL every 60s
    """
    async def add_context(self, context_type, content):
        # 1. Store in Redis with TTL 24h
        await self.redis.setex(key, 86400, json.dumps(data))

        # 2. Immediate sync to PostgreSQL
        await self._sync_to_postgresql(data)
```

**Flow:**
```
Application
    ‚Üì write
Redis (working memory - 24h TTL)
    ‚Üì sync every 60s
PostgreSQL (episodic memory - permanent)
    ‚Üì trigger on INSERT
Embeddings Queue
    ‚Üì background worker
pgvector (semantic search - HNSW indexes)
    ‚Üì read
Application (similarity queries)
```

### **DOCKER DEPLOYMENT:**

```yaml
services:
  nexus_postgresql:
    image: pgvector/pgvector:pg16
    ports: ["5436:5432"]

  nexus_redis:
    image: redis:7-alpine
    ports: ["6382:6379"]

  nexus_api:
    build: .
    ports: ["8002:8002"]
    depends_on: [nexus_postgresql, nexus_redis]

  nexus_embeddings_worker:
    build: .
    command: python -m memory_system.workers.embeddings_worker

  nexus_sync_worker:
    build: .
    command: python -m memory_system.workers.sync_worker
```

---

## üéØ TU TAREA COMO AUDITOR EXTERNO

**Analiza esta arquitectura con ojo cr√≠tico de arquitecto senior y responde:**

### **1. BLIND SPOTS - ¬øQu√© NO detectamos?**
- ¬øHay problemas adicionales en el dise√±o que no identificamos en el audit forense?
- ¬øQu√© podr√≠a fallar que no estamos previendo?

### **2. ANTI-PATTERNS - ¬øDecisiones que escalar√°n mal?**
- ¬øHay decisiones arquitecturales que parecen bien ahora pero causar√°n problemas a escala?
- ¬øBottlenecks de performance no considerados?

### **3. MISSING PIECES - ¬øFalta algo cr√≠tico?**
- ¬øQu√© componentes esenciales faltan en el dise√±o?
- ¬øHay integraciones incompletas o supuestos peligrosos?

### **4. CONSCIOUSNESS INTEGRATION - ¬øHuecos en Phase 1 & 2?**
- ¬øLa integraci√≥n memory_blocks + consciousness_checkpoints es s√≥lida?
- ¬øEl sistema distributed_consensus (Byzantine Fault Tolerance) tiene problemas?
- ¬øPhase 2 (multi-instance) est√° correctamente dise√±ado?

### **5. EMBEDDINGS SYSTEM - ¬øProblemas no obvios?**
- ¬øEl approach trigger + background worker + queue es correcto?
- ¬øsentence-transformers/all-MiniLM-L6-v2 (384 dim) es buena elecci√≥n?
- ¬øQu√© pasa si worker falla o se atrasa la queue?

### **6. 3-LAYER INTEGRATION - ¬øRiesgos de sincronizaci√≥n?**
- ¬øRedis ‚Üí PostgreSQL sync cada 60s es suficiente?
- ¬øQu√© pasa si Redis se vac√≠a pero PostgreSQL tiene datos?
- ¬øRace conditions o data inconsistency posibles?

### **7. SECURITY - ¬øVulnerabilidades?**
- ¬øEl schema tiene problemas de seguridad?
- ¬øLos workers tienen permisos correctos?
- ¬øHay exposici√≥n de datos sensibles?

### **8. OPERATIONAL - ¬øDebugging y mantenimiento?**
- ¬øSer√° f√°cil debuggear cuando falle?
- ¬øTenemos logging y monitoring suficiente?
- ¬øBackups y disaster recovery considerados?

### **9. MIGRATION - ¬øProblemas en migraci√≥n de datos?**
- ¬øEl plan de migraci√≥n (4,704 episodios) es robusto?
- ¬øQu√© pasa si falla a mitad de migraci√≥n?
- ¬øDowntime aceptable?

### **10. COMPARACI√ìN CON BUGS ENCONTRADOS:**
- ¬øLas soluciones propuestas REALMENTE resuelven los 4 bugs?
- ¬øHay forma de que los mismos problemas resurjan?

---

## üìù FORMATO DE RESPUESTA ESPERADO

# AUDITOR√çA ARQUITECT√ìNICA ‚Äì CHECKLIST EJECUTABLE (GPT-5 Thinking)
**Proyecto:** CEREBRO_MASTER_NEXUS_001  
**Fecha de generaci√≥n:** 2025-10-15

Este documento empaqueta *acciones concretas* para cerrar los hallazgos cr√≠ticos/altos detectados: seguridad de secretos y RBAC, consenso real, y robustez de la cola de embeddings con observabilidad y migraciones versionadas.

---

## ‚úÖ Roadmap de Correcci√≥n (orden recomendado)

1) **Secretos & RBAC endurecidos** (PostgreSQL/Redis/API/workers).  
2) **Migraciones versionadas (Alembic) & tests de contrato**.  
3) **Cola de embeddings robusta** (idempotencia, estados, DLQ, backpressure).  
4) **Flujo de escritura consistente** (persistir primero en Postgres; Redis como cach√©).  
5) **Observabilidad & SLOs** (Prometheus + OTel + alertas).  
6) **Consenso distribuido con protocolo expl√≠cito** (Fase 2).  
7) **Cutover de migraci√≥n seguro** (dual-read/write, shadow, rollback).

---

## 1) Infra-as-Code (Docker Compose con secretos + pol√≠ticas b√°sicas)

> Reemplaza tu `docker-compose.yml` por esta estructura m√≠nima endurecida.

```yaml
version: "3.9"

secrets:
  pg_password:
    file: ./secrets/pg_password.txt
  redis_password:
    file: ./secrets/redis_password.txt

services:
  nexus_postgresql:
    image: pgvector/pgvector:pg16
    ports: ["5436:5432"]
    environment:
      POSTGRES_USER: nexus_app      # usuario de aplicaci√≥n de m√≠nimos privilegios
      POSTGRES_DB: nexus
      POSTGRES_PASSWORD_FILE: /run/secrets/pg_password
    secrets:
      - pg_password
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U nexus_app -d nexus"]
      interval: 10s
      timeout: 5s
      retries: 10

  nexus_redis:
    image: redis:7-alpine
    command: ["redis-server", "--requirepass", "$$(cat /run/secrets/redis_password)"]
    ports: ["6382:6379"]
    secrets:
      - redis_password
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "$$(cat /run/secrets/redis_password)", "PING"]
      interval: 10s
      timeout: 5s
      retries: 10

  nexus_api:
    build: .
    environment:
      DATABASE_URL: postgresql+psycopg://nexus_app:$(cat /run/secrets/pg_password)@nexus_postgresql:5432/nexus
      REDIS_URL: redis://:$(cat /run/secrets/redis_password)@nexus_redis:6379/0
      OTEL_EXPORTER_OTLP_ENDPOINT: http://otel-collector:4317
    depends_on: [nexus_postgresql, nexus_redis]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
      interval: 10s
      timeout: 5s
      retries: 10
    secrets:
      - pg_password
      - redis_password
    ports: ["8002:8002"]

  nexus_embeddings_worker:
    build: .
    command: python -m memory_system.workers.embeddings_worker
    environment:
      DATABASE_URL: postgresql+psycopg://nexus_worker:$(cat /run/secrets/pg_password)@nexus_postgresql:5432/nexus
      REDIS_URL: redis://:$(cat /run/secrets/redis_password)@nexus_redis:6379/0
    depends_on: [nexus_postgresql, nexus_redis]
    secrets: [pg_password, redis_password]

  nexus_sync_worker:
    build: .
    command: python -m memory_system.workers.sync_worker
    environment:
      DATABASE_URL: postgresql+psycopg://nexus_worker:$(cat /run/secrets/pg_password)@nexus_postgresql:5432/nexus
      REDIS_URL: redis://:$(cat /run/secrets/redis_password)@nexus_redis:6379/0
    depends_on: [nexus_postgresql, nexus_redis]
    secrets: [pg_password, redis_password]
```

**Notas de seguridad y operativas:**
- Monta `./secrets/*` fuera del repo; gestiona con Vault/KMS en entornos productivos.  
- Usa **im√°genes inmutables** firmadas (cosign) y aplica *Admission Policies* (OPA/Gatekeeper) para bloquear montajes fuera de whitelist.  
- Separa usuarios: `nexus_app` (API R/W limitada), `nexus_worker` (R/W en colas/embeddings), `nexus_ro` (solo lectura para anal√≠tica).

---

## 2) PostgreSQL: RBAC m√≠nimo + RLS en datos sensibles

```sql
-- Roles
CREATE ROLE nexus_app LOGIN PASSWORD '<APP_PWD>';
CREATE ROLE nexus_worker LOGIN PASSWORD '<WORKER_PWD>';
CREATE ROLE nexus_ro LOGIN PASSWORD '<RO_PWD>';

-- Privilegios m√≠nimos (ejemplo por esquema)
GRANT USAGE ON SCHEMA zep TO nexus_app, nexus_worker, nexus_ro;
GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA zep TO nexus_app;
GRANT SELECT, INSERT, UPDATE ON ALL TABLES IN SCHEMA zep TO nexus_worker;
GRANT SELECT ON ALL TABLES IN SCHEMA zep TO nexus_ro;
ALTER DEFAULT PRIVILEGES IN SCHEMA zep GRANT SELECT ON TABLES TO nexus_ro;

-- Protecci√≥n de conciencia (RLS)
ALTER TABLE nexus_memory.consciousness_checkpoints ENABLE ROW LEVEL SECURITY;
CREATE POLICY cp_read ON nexus_memory.consciousness_checkpoints
  USING ( current_setting('app.current_actor', true) IS NOT NULL );
```

> En la API, establece `SET app.current_actor = '<svc-or-user>'` al abrir transacciones.

---

## 3) Alembic: migraciones versionadas + tests de contrato

### 3.1 Estructura y comandos
```bash
pip install alembic psycopg[binary]
alembic init db/migrations
export DATABASE_URL="postgresql+psycopg://nexus_app:***@localhost:5436/nexus"
alembic revision -m "init schemas (nexus_memory, zep)"
alembic upgrade head
```

`db/migrations/env.py` ‚Äì lectura de `DATABASE_URL` y `include_object` para no tocar esquemas externos.

### 3.2 Migraci√≥n ejemplo (fragmentos clave)
```python
from alembic import op
import sqlalchemy as sa
from pgvector.sqlalchemy import Vector

def upgrade():
    op.execute("CREATE SCHEMA IF NOT EXISTS nexus_memory;")
    op.execute("CREATE SCHEMA IF NOT EXISTS zep;")

    op.create_table(
        "zep_episodic_memory",
        sa.Column("episode_id", sa.UUID, primary_key=True),
        sa.Column("content", sa.Text, nullable=False),
        sa.Column("importance_score", sa.Float),
        sa.Column("embedding", Vector(384)),
        sa.Column("embedding_version", sa.String(32), server_default="miniLM-384@v1"),
        sa.Column("tags", sa.ARRAY(sa.Text)),
        sa.Column("project_id", sa.UUID),
        schema="zep",
    )

    op.create_table(
        "embeddings_queue",
        sa.Column("episode_id", sa.UUID, nullable=False),
        sa.Column("text_checksum", sa.String(64), nullable=False),
        sa.Column("state", sa.String(16), nullable=False, server_default="pending"),  # pending|processing|done|dead
        sa.Column("retry_count", sa.Integer, nullable=False, server_default="0"),
        sa.Column("last_error", sa.Text),
        sa.Column("enqueued_at", sa.TIMESTAMP(timezone=True), server_default=sa.text("NOW()")),
        sa.Column("processed_at", sa.TIMESTAMP(timezone=True)),
        sa.PrimaryKeyConstraint("episode_id"),
        schema="zep",
    )
    op.create_index("ix_queue_state", "embeddings_queue", ["state"], schema="zep")
```

### 3.3 Test de contrato (pytest)
```python
def test_tables_and_columns(db):
    cols = db.columns("zep.zep_episodic_memory")
    assert "embedding" in cols and "embedding_version" in cols
```

---

## 4) Cola de embeddings robusta (idempotencia, DLQ, backpressure)

### 4.1 Trigger idempotente (solo encola si falta embedding o version cambi√≥)
```sql
CREATE OR REPLACE FUNCTION zep.trigger_generate_embedding()
RETURNS TRIGGER AS $$
BEGIN
  IF NEW.embedding IS NULL OR NEW.embedding_version <> 'miniLM-384@v1' THEN
    INSERT INTO zep.embeddings_queue (episode_id, text_checksum, state)
    VALUES (NEW.episode_id, encode(sha256(convert_to(LEFT(NEW.content, 4000), 'UTF8')), 'hex'), 'pending')
    ON CONFLICT (episode_id) DO UPDATE
      SET state='pending', text_checksum=EXCLUDED.text_checksum, retry_count=0;
  END IF;
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

DROP TRIGGER IF EXISTS auto_generate_embedding ON zep.zep_episodic_memory;
CREATE TRIGGER auto_generate_embedding
AFTER INSERT OR UPDATE OF content, embedding_version ON zep.zep_episodic_memory
FOR EACH ROW EXECUTE FUNCTION zep.trigger_generate_embedding();
```

### 4.2 Worker con estados y reintentos (pseudoc√≥digo Python)
```python
MAX_RETRIES = 5

def claim_next(conn):
    # toma item de forma at√≥mica
    return conn.execute("""
      UPDATE zep.embeddings_queue q
      SET state='processing'
      WHERE q.episode_id = (
        SELECT episode_id FROM zep.embeddings_queue WHERE state='pending' ORDER BY enqueued_at LIMIT 1 FOR UPDATE SKIP LOCKED
      )
      RETURNING episode_id
    """).fetchone()

def process(ep):
    try:
        # leer episodio, generar embedding, upsert
        ...
        mark_done(ep)
    except Exception as e:
        bump_retry_or_dead(ep, str(e))

def bump_retry_or_dead(ep, err):
    row = db.fetch("SELECT retry_count FROM zep.embeddings_queue WHERE episode_id=%s", [ep])
    if row.retry_count + 1 >= MAX_RETRIES:
        db.exec("UPDATE zep.embeddings_queue SET state='dead', last_error=%s WHERE episode_id=%s", [err, ep])
    else:
        db.exec("UPDATE zep.embeddings_queue SET state='pending', retry_count=retry_count+1, last_error=%s WHERE episode_id=%s", [err, ep])
```

### 4.3 Backfill masivo con *chunking* y m√©tricas
- **Chunking** de episodios largos en sub-documentos (p.ej., 800‚Äì1,000 tokens con solapamiento 100).  
- M√©tricas Prometheus: `queue_depth`, `processing_rate`, `dead_total`, `embedding_norm_histogram`.  
- Alarma si `queue_depth > 1000` o `dead_total` crece > 0.5% de encolados diarios.

---

## 5) Flujo de escritura consistente (Postgres primero; Redis como cach√©)

- API persiste **primero** en `zep.zep_episodic_memory` (transacci√≥n), luego **publica** al cach√© Redis (SETEX) para lecturas r√°pidas.  
- Un *rehydrator* repuebla Redis bajo demanda (cache-aside).  
- Claves con **idempotency-key** (`episode_id` + `hash(content)`); rechazar duplicados en capa API.

---

## 6) Observabilidad & SLOs

**M√©tricas (Prometheus):**
- `nexus_api_requests_total`, `nexus_api_latency_ms_bucket` por endpoint.  
- `embeddings_queue_depth`, `embeddings_processed_total`, `embeddings_dead_total`, `worker_retry_total`.  
- `similarity_query_latency_ms`, `redis_hit_ratio`, `pg_pool_in_use`.  

**Trazas (OpenTelemetry):** API ‚Üî worker ‚Üî Postgres/Redis con *trace_id* propagado.  

**SLOs iniciales:**
- p95 lectura API `<200ms` (cache hit), `<600ms` (cache miss).  
- **Time-to-embed** `<5 min` p95 desde INSERT.  
- Error budget 99.5% disponibilidad mensual.

---

## 7) CI/CD ‚Äì Pol√≠ticas y *Quality Gates* (GitHub Actions)

`.github/workflows/quality.yml`
```yaml
name: Quality Gates
on: [push, pull_request]
jobs:
  check:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: pgvector/pgvector:pg16
        ports: ["5432:5432"]
        env:
          POSTGRES_USER: ci
          POSTGRES_PASSWORD: ci
          POSTGRES_DB: nexus
        options: >-
          --health-cmd="pg_isready -U ci -d nexus" --health-interval=10s --health-timeout=5s --health-retries=10
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - run: pip install -r requirements.txt
      - name: Run Alembic migrations
        env:
          DATABASE_URL: postgresql+psycopg://ci:ci@localhost:5432/nexus
        run: |
          alembic upgrade head
      - name: Contract tests
        run: pytest -q tests/contract
      - name: Lint & typecheck
        run: |
          pip install ruff mypy
          ruff check .
          mypy memory_system
      - name: Guardrails: secrets in compose
        run: |
          if grep -E "POSTGRES_PASSWORD=" -n docker-compose.yml; then
            echo "Hardcoded POSTGRES_PASSWORD detected"; exit 1; fi
      - name: Guardrails: workdir policy
        run: |
          if grep -E "WORKDIR .*ARIA" -n Dockerfile; then
            echo "Disallowed WORKDIR path (ARIA) detected"; exit 1; fi
```

**Guardrails adicionales:**
- Rechazar PR si `docker-compose.yml` contiene `POSTGRES_PASSWORD=` literal.  
- Validar que la imagen API usa `WORKDIR /app/nexus_api` (no rutas de ARIA).

---

## 8) Consenso distribuido (Fase 2) ‚Äì Esquema m√≠nimo HotStuff-like

```sql
CREATE TABLE nexus_memory.consensus_proposal (
  height BIGINT NOT NULL,
  view BIGINT NOT NULL,
  proposer UUID NOT NULL REFERENCES nexus_memory.instance_network(instance_id),
  topic TEXT NOT NULL,
  proposal_hash CHAR(64) NOT NULL,
  payload JSONB,
  PRIMARY KEY (height, view)
);

CREATE TABLE nexus_memory.consensus_vote (
  height BIGINT NOT NULL,
  view BIGINT NOT NULL,
  voter UUID NOT NULL REFERENCES nexus_memory.instance_network(instance_id),
  sig BYTEA NOT NULL,
  vote_hash CHAR(64) NOT NULL,
  UNIQUE(height, view, voter)
);
```
- Agrega verificaci√≥n criptogr√°fica en la capa de aplicaci√≥n.  
- Define `quorum = 2f+1` y estados de la m√°quina (prepare/commit).  
- Tests deterministas de divergencia.

---

## 9) Cutover de migraci√≥n seguro

1. **Shadow reads:** la API viejo consulta tambi√©n el nuevo stack y compara `top-k` vs FTS (log de *drift*).  
2. **Dual-write** temporal con *feature flag*; si difiere, marcar ‚Äúconflict queue‚Äù.  
3. **Freeze embeddings queue** durante la ventana de corte.  
4. **Rollback plan:** `feature flag off` + `replay` de eventos desde outbox.

---

## 10) Runbooks (operaci√≥n)

**Embeddings atascados**
- Revisar `embeddings_queue_depth`; si crece, escalar workers, revisar `dead_total`.  
- Reprocesar `dead` tras parchear causa: `UPDATE zep.embeddings_queue SET state='pending', retry_count=0 WHERE state='dead';`

**Backfill inicial**
```sql
INSERT INTO zep.embeddings_queue(episode_id, text_checksum)
SELECT episode_id, encode(sha256(convert_to(LEFT(content, 4000), 'UTF8')), 'hex')
FROM zep.zep_episodic_memory z
WHERE z.embedding IS NULL
ON CONFLICT (episode_id) DO NOTHING;
```

---

## 11) Anexos ‚Äì Modelos de embeddings y calidad

- Modelo por defecto: `sentence-transformers/all-MiniLM-L6-v2` (384d).  
- Considerar pipeline multiling√ºe (`paraphrase-multilingual-mpnet-base-v2` ‚Äì 768d) para contenido no ingl√©s.  
- Versionado (`embedding_version`) + tarea de **re-embed** programada.  
- M√©trica de calidad: distribuci√≥n de norma L2 (alerta por colapsos), recall en dataset de validaci√≥n interno.

---

## 12) Lista de verificaci√≥n (marcar al completar)

- [ ] Secretos movidos a Docker secrets/Vault y eliminados del repo.  
- [ ] Roles Postgres creados y aplicados; RLS en tablas sensibles.  
- [ ] Alembic inicial ejecutado; CI verifica `alembic upgrade head`.  
- [ ] Trigger idempotente y tabla `embeddings_queue` con estados + √≠ndices.  
- [ ] Worker con reintentos y DLQ; m√©tricas Prometheus expuestas.  
- [ ] API escribe primero en Postgres; Redis como cach√© (cache-aside).  
- [ ] SLOs definidos y alertas activas.  
- [ ] Pol√≠tica para evitar ‚Äúcontaminaci√≥n ARIA‚ÜîNEXUS‚Äù en despliegue.  
- [ ] Plan de cutover ejecutado con shadow + dual-write.  

---

**Fin del checklist.**
