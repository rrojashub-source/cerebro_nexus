# üî¨ LAB_011: Working Memory Buffer

**Status:** ‚úÖ COMPLETE
**Start Date:** October 28, 2025
**Completion Date:** October 28, 2025
**Researchers:** NEXUS (Autonomous)
**Priority:** HIGH
**Actual Duration:** 2 hours

---

## üéØ Hypothesis

**Not all memories should be in long-term storage all the time - NEXUS needs a limited-capacity "active workspace" for currently relevant information.**

Like human working memory (dorsolateral prefrontal cortex), NEXUS should maintain a small buffer (~7 items) of immediately accessible memories for current tasks, with automatic eviction and refresh.

---

## üß† Neuroscience Basis

### Human Working Memory

**Core Regions:**
- **Dorsolateral prefrontal cortex (dlPFC):** Active maintenance of information
- **Parietal cortex:** Attentional refreshing and manipulation
- **Anterior cingulate:** Conflict monitoring and buffer updates

**Key Properties:**
1. **Limited capacity:** 7¬±2 items (Miller's Law, 1956)
2. **Short duration:** Seconds to minutes without rehearsal
3. **Active maintenance:** Items actively "held online" for immediate use
4. **Rehearsal:** Repetition keeps items alive
5. **Eviction:** Irrelevant items automatically dropped

### AI Parallel (Transformer KV Cache)

```
Transformer KV Cache:
Limited cache of key-value pairs for recent context
Fast access, automatic eviction (sliding window)

Working Memory Buffer (LAB_011):
Limited buffer of episode IDs for current task
Fast in-memory access, attention-based eviction
```

---

## üîß What We're Building

### Working Memory Buffer System

**Input:** Episodes from attention mechanism (LAB_010) or explicit additions
**Process:** Maintain 7-item buffer with smart eviction
**Output:** Fast access to currently relevant memories

### Architecture Components

#### 1. **WorkingMemoryBuffer**
```python
class WorkingMemoryBuffer:
    """Limited-capacity buffer for currently active memories"""

    def __init__(self, capacity: int = 7):
        """
        Args:
            capacity: Buffer size (default: 7, Miller's Law)
        """
        self.capacity = capacity
        self.buffer: List[WorkingMemoryItem] = []

    def add(self, episode_id: str, attention_weight: float = 1.0):
        """
        Add episode to working memory.
        Evicts least relevant if buffer full.
        """
        pass

    def get(self, episode_id: str) -> Optional[WorkingMemoryItem]:
        """Fast O(1) access to buffered item"""
        pass

    def refresh(self, episode_id: str):
        """Rehearsal - reset decay timer for item"""
        pass

    def decay_step(self):
        """Temporal decay - remove stale items"""
        pass
```

#### 2. **EvictionPolicy**
```python
class EvictionPolicy:
    """Determine which item to evict when buffer full"""

    def select_victim(
        self,
        buffer: List[WorkingMemoryItem],
        new_item: WorkingMemoryItem
    ) -> int:
        """
        Select item to evict.

        Strategies:
        - LRU (Least Recently Used)
        - Attention-based (lowest attention weight)
        - Hybrid (LRU + attention)
        """
        pass
```

#### 3. **RehearsalManager**
```python
class RehearsalManager:
    """Manage rehearsal (keeping items alive)"""

    def should_rehearse(self, item: WorkingMemoryItem) -> bool:
        """
        Decide if item should be rehearsed.

        Criteria:
        - High attention weight
        - Frequently accessed
        - Task-relevant tags
        """
        pass
```

#### 4. **BufferManager**
```python
class BufferManager:
    """Main orchestrator for working memory"""

    def update_from_attention(
        self,
        attended_episodes: List[Tuple[str, float]]
    ):
        """Update buffer based on attention weights"""
        pass

    def get_active_context(self) -> List[str]:
        """Get all currently buffered episode IDs"""
        pass
```

---

## üìä Success Metrics

### Quantitative

1. **Capacity Limit Respected**
   - Target: Buffer never exceeds 7 items
   - Measure: max(buffer_size) ‚â§ 7

2. **Fast Access**
   - Target: <1ms for buffered item retrieval
   - Measure: get() operation latency

3. **Smart Eviction**
   - Target: High-attention items stay longer
   - Measure: Correlation(attention_weight, retention_time)

4. **Temporal Decay**
   - Target: Unused items decay and are removed
   - Measure: Items not accessed for >30 steps evicted

### Qualitative

- Does buffer contain currently relevant memories?
- Are irrelevant memories quickly evicted?
- Does rehearsal keep important items alive?

---

## üõ†Ô∏è Implementation Plan

### Phase 1: Design (15 min) ‚úÖ
- [x] Neuroscience research
- [x] Architecture design

### Phase 2: Core Implementation (45 min) ‚úÖ
- [x] WorkingMemoryItem dataclass
- [x] WorkingMemoryBuffer class
- [x] LRU eviction policy
- [x] Attention-based eviction policy
- [x] Temporal decay mechanism

### Phase 3: Advanced Features (30 min) ‚úÖ
- [x] RehearsalManager
- [x] BufferManager orchestrator
- [x] Integration with LAB_010 (attention)

### Phase 4: Testing (30 min) ‚úÖ
- [x] Test capacity limits
- [x] Test eviction policies
- [x] Test temporal decay
- [x] Test rehearsal

### Phase 5: Documentation (15 min) ‚úÖ
- [x] RESULTS.md
- [x] Update README
- [x] Git commit

---

## üí° Expected Outcomes

### If Successful

**Working memory buffer:**
- Maintains 7 currently relevant episodes
- Fast access (<1ms for buffered items)
- Smart eviction (keeps high-attention items)
- Automatic decay (removes stale items)
- Rehearsal (keeps important items alive)

**Example:**

```
Working Memory Buffer (7/7 items):
1. LAB_010 attention mechanism     [attention: 0.9, age: 2 steps]
2. LAB_011 working memory design   [attention: 0.8, age: 1 step]
3. LAB_009 reconsolidation results [attention: 0.7, age: 5 steps] (rehearsed)
4. LAB_005 spreading activation    [attention: 0.6, age: 3 steps]
5. Current task context            [attention: 0.5, age: 1 step]
6. User preference: "autonomous"   [attention: 0.4, age: 10 steps] (rehearsed)
7. Error from LAB_007              [attention: 0.3, age: 4 steps]

New item arrives (attention: 0.85)
‚Üí Evict item #7 (lowest attention, not rehearsed)
‚Üí Add new item to buffer
```

---

## üîó Integration with Other LABS

### LAB_010: Attention Mechanism
**Integration:** Attention output feeds working memory
- High-attention episodes automatically added to buffer
- Attention weights guide eviction policy

### LAB_005: Spreading Activation
**Integration:** Buffered episodes activate related memories
- Items in working memory are "source nodes" for spreading
- Stronger activation from buffered items

### LAB_009: Memory Reconsolidation
**Integration:** Buffered memories reconsolidated more strongly
- Items that persist in buffer get stronger consolidation
- Rehearsal triggers reconsolidation

### LAB_007: Predictive Preloading
**Integration:** Predicted memories pre-loaded into buffer
- High-confidence predictions added to buffer
- Speeds up retrieval for expected memories

---

## üìö References

### Neuroscience
- Miller (1956) - "The Magical Number Seven, Plus or Minus Two"
- Baddeley & Hitch (1974) - Working memory model
- Cowan (2001) - Capacity limits of working memory
- Recent 2024-2025 studies on dlPFC maintenance mechanisms

### AI/ML
- Transformer KV cache (attention caching)
- LRU cache algorithms (eviction policies)
- Memory-augmented neural networks (2024)

---

## üéì Design Decisions

### Why 7 items?
**Miller's Law (1956):** Human working memory capacity is 7¬±2 items
- Empirically validated across decades of research
- Balances utility (enough context) vs. limitations (focused attention)
- Maps to modern neuroscience (dlPFC capacity limits)

### Why attention-based eviction?
**Relevance > recency:** Items with high attention should stay, even if not recently accessed
- LRU alone: May evict important but not-recently-touched items
- Attention-based: Keeps task-relevant items regardless of recency
- Hybrid (LRU + attention): Best of both worlds

### Why temporal decay?
**Realism:** Human working memory items decay without rehearsal
- Prevents buffer from becoming "long-term storage"
- Forces system to actively maintain important items
- Creates "cognitive load" similar to human constraints

---

**Status:** Design complete, moving to implementation

**Next Step:** Implement WorkingMemoryBuffer core

---

**Created by:** NEXUS (Autonomous)
**Philosophy:** "Working memory is the mind's workbench - limited, fast, and task-focused."
