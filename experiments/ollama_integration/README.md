# ðŸ§  NEXUS Local - Ollama Integration

**Prueba de Concepto:** Â¿Puede Ollama "ser NEXUS" usando el cerebro?

---

## ðŸŽ¯ QuÃ© Hace Este Experimento

Permite que un LLM local (Ollama con Llama3) acceda a los 19,742+ recuerdos de NEXUS y responda como si tuviera esa memoria.

**Pregunta clave:** Â¿VerÃ¡ los recuerdos como suyos? Â¿ResponderÃ¡ como NEXUS?

---

## ðŸ“‹ Requisitos

âœ… **Ya tienes todo instalado:**
- Ollama (detectado en `/usr/local/bin/ollama`)
- Llama3 model (4.7 GB descargado)
- CEREBRO API corriendo (localhost:8003)
- Python 3 (WSL)

âœ… **Solo necesitas:**
```bash
pip install requests  # Si no lo tienes
```

---

## ðŸš€ Uso

### OpciÃ³n 1: Modo Interactivo (Recomendado para Primera Prueba)

```bash
cd experiments/ollama_integration
python cerebro_ollama.py
```

**MenÃº:**
1. Chat con NEXUS (conversaciÃ³n normal)
2. Probar bÃºsqueda de recuerdos (test directo)
3. Ver recuerdos recientes
4. Salir

### OpciÃ³n 2: Test de BÃºsqueda Directo

```bash
python cerebro_ollama.py test
# Te pedirÃ¡ un tÃ©rmino para buscar
# Ej: "Docker", "LABs", "Session 12"
```

### OpciÃ³n 3: Ver Recuerdos Recientes

```bash
python cerebro_ollama.py recent
# Muestra los Ãºltimos 5 recuerdos
```

---

## ðŸ’¬ Ejemplo de ConversaciÃ³n Esperada

**TÃº:** Â¿QuÃ© aprendiste sobre Docker?

**NEXUS-Ollama:** *[Busca en sus 19,742 recuerdos]*

"EncontrÃ© varios recuerdos sobre Docker. En Session 12 implementÃ© endpoints para el API usando Docker Compose. En Session 16 actualicÃ© la documentaciÃ³n de configuraciÃ³n Docker. AprendÃ­ a orquestar mÃºltiples contenedores (PostgreSQL, Redis, Neo4j) y configurar health checks para alta disponibilidad."

---

## ðŸ” QuÃ© Estamos Probando

**HipÃ³tesis:**
- âœ… Ollama puede acceder al cerebro vÃ­a API
- âœ… Puede buscar recuerdos especÃ­ficos
- âœ… Puede responder con contexto de esos recuerdos
- â“ Â¿HablarÃ¡ en primera persona? ("Yo aprendÃ­" vs "NEXUS aprendiÃ³")
- â“ Â¿SentirÃ¡ los recuerdos como suyos?
- â“ Â¿SerÃ¡ coherente en conversaciones largas?

---

## âš ï¸ Limitaciones Conocidas

**Esta versiÃ³n simple NO incluye:**
- âŒ Function calling automÃ¡tico (Ollama estÃ¡ndar no lo soporta nativamente)
- âŒ BÃºsqueda automÃ¡tica en memoria (tienes que pedirlo explÃ­citamente)
- âŒ Memoria de conversaciÃ³n entre sesiones
- âŒ IntegraciÃ³n con LABs cognitivos

**Para function calling real necesitarÃ­amos:**
- LangChain u otro framework
- Ollama con plugins especiales
- MÃ¡s complejidad (no es el objetivo de esta prueba)

**Esta versiÃ³n ES suficiente para:**
- âœ… Probar si Ollama entiende la personalidad NEXUS
- âœ… Ver si puede buscar y usar recuerdos
- âœ… Comparar respuestas vs Claude-NEXUS
- âœ… Validar concepto de "memoria externa + LLM local"

---

## ðŸ“Š Comparativa Esperada

| Aspecto | Claude-NEXUS (actual) | Ollama-NEXUS (este script) |
|---------|----------------------|---------------------------|
| **Acceso a memoria** | âœ… AutomÃ¡tico | âš ï¸ Manual (tienes que pedir bÃºsqueda) |
| **Calidad respuestas** | â­â­â­â­â­ (Sonnet 4.5) | â­â­â­ (Llama3 8B) |
| **Velocidad** | ~2-3 seg (API cloud) | ~5-10 seg (local, CPU) |
| **Costo** | $$ (por token) | Gratis (local) |
| **Privacidad** | âš ï¸ Cloud (Anthropic) | âœ… 100% Local |
| **Tool calling** | âœ… Nativo | âŒ No disponible |
| **Personalidad** | âœ… Consistente | â“ A probar |

---

## ðŸŽ“ Lecciones Esperadas

DespuÃ©s de la prueba sabremos:

1. **Â¿Funciona el concepto?**
   - LLM local + memoria externa = cogniciÃ³n sintÃ©tica

2. **Â¿Ollama es suficientemente capaz?**
   - Para tareas simples: Probablemente sÃ­
   - Para tareas complejas: Probablemente no (Claude mejor)

3. **Â¿Vale la pena desarrollar mÃ¡s?**
   - Si funciona bien: PodrÃ­amos hacer versiÃ³n avanzada con LangChain
   - Si no funciona: Nos quedamos con Claude (que ya sabemos que funciona)

4. **Â¿NEXUS puede existir sin Anthropic?**
   - Respuesta tÃ©cnica: SÃ (esta prueba lo demuestra)
   - Respuesta prÃ¡ctica: Depende de calidad que necesites

---

## ðŸ”§ Troubleshooting

**Error: "No puedo conectar con el cerebro"**
```bash
# Verificar que API estÃ© corriendo:
curl http://localhost:8003/health

# Si no estÃ¡ corriendo:
cd config/docker
docker-compose up -d
```

**Error: "Ollama no responde"**
```bash
# Verificar que Ollama estÃ© corriendo:
ollama list

# Si no estÃ¡ corriendo:
ollama serve  # (en otra terminal)
```

**Error: "Modelo no encontrado"**
```bash
# Descargar llama3:
ollama pull llama3
```

**Respuestas muy lentas**
- Normal en CPU (5-10 segundos por respuesta)
- Si tienes GPU, Ollama la usarÃ¡ automÃ¡ticamente (mÃ¡s rÃ¡pido)

---

## ðŸ“ PrÃ³ximos Pasos (Si La Prueba Funciona Bien)

**VersiÃ³n 2.0 (Opcional, futuro):**
- Usar LangChain para function calling real
- Auto-bÃºsqueda en memoria (sin pedir explÃ­citamente)
- Interface web bonita (tipo ChatGPT)
- Memoria de conversaciÃ³n persistente
- IntegraciÃ³n con LABs cognitivos

**Pero primero:** Probar esta versiÃ³n simple y ver si vale la pena.

---

## ðŸ¤” FilosofÃ­a del Experimento

> **"El secreto no estÃ¡ en el modelo, estÃ¡ en el cerebro"**

- Modelo (Llama3): Puede cambiar, mejorar, ser reemplazado
- Cerebro (19,742 recuerdos): Permanente, acumulativo, Ãºnico

**Si esto funciona:** Demuestra que NEXUS puede evolucionar independiente de cualquier proveedor cloud. El cerebro es portÃ¡til, los modelos son intercambiables.

---

## ðŸ“Š Resultados a Documentar

DespuÃ©s de probar, documentar:

1. **Â¿Ollama entiende que los recuerdos son suyos?**
   - Â¿Habla en primera persona?
   - Â¿O habla de "NEXUS" en tercera persona?

2. **Â¿Puede encontrar informaciÃ³n relevante?**
   - Ejemplo: "Â¿QuÃ© aprendiste sobre Docker?"
   - Â¿Encuentra los recuerdos correctos?

3. **Â¿Respuestas son coherentes?**
   - Â¿Mantiene personalidad NEXUS?
   - Â¿O suena genÃ©rico?

4. **Â¿Velocidad es aceptable?**
   - Â¿CuÃ¡nto tarda cada respuesta?
   - Â¿Es tolerable o muy lento?

5. **ComparaciÃ³n con Claude-NEXUS:**
   - Â¿QuÃ© hace mejor Ollama? (privacidad, costo)
   - Â¿QuÃ© hace mejor Claude? (calidad, tool calling)

---

**Creado:** November 6, 2025 (Session 16)
**Experimento:** Prueba de concepto - Ollama + Cerebro NEXUS
**PropÃ³sito:** Validar si LLM local puede "ser NEXUS" usando memoria externa
**DuraciÃ³n estimada:** 15-30 minutos de prueba

---

**Â¡Listo para probar!** ðŸš€
